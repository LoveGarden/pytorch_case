{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#1 å¼ é‡åˆ›å»ºï¼šä»æ— åˆ°æœ‰æ„å»ºåŸºç¡€å•å…ƒ\n",
        "\n",
        "tesoræ˜¯PyTorchçš„æ ¸å¿ƒæ•°æ®ç»“æ„ï¼Œç±»ä¼¼NumPyæ•°ç»„ï¼Œä½†æ”¯æŒGPUåŠ é€Ÿå’Œè‡ªåŠ¨å¾®åˆ†ã€‚ä»¥ä¸‹æ˜¯æœ€å¸¸ç”¨çš„åˆ›å»ºæ–¹å¼ï¼š\n",
        "\n",
        "| op  | åŠŸèƒ½æè¿°| å…³é”®å‚æ•° |\n",
        "|----------|----------|----------|\n",
        "|torch.tensor|\tä»åˆ—è¡¨/å…ƒç»„/NumPyæ•°ç»„è½¬æ¢ä¸ºå¼ é‡|\tdata(è¾“å…¥æ•°æ®)ã€requires_grad(æ˜¯å¦è¿½æ¢¯åº¦)|\n",
        "|torch.zeros|\tç”Ÿæˆå…¨0å¼ é‡\t|size(å¼ é‡å½¢çŠ¶ï¼Œå¦‚(2,3))|\n",
        "|torch.ones|\tç”Ÿæˆå…¨1å¼ é‡\t|size(å¼ é‡å½¢çŠ¶)|\n",
        "|torch.rand|\tç”Ÿæˆ[0,1)å‡åŒ€åˆ†å¸ƒçš„éšæœºå¼ é‡\t|size(å¼ é‡å½¢çŠ¶)|\n",
        "|torch.randn|\tç”Ÿæˆå‡å€¼0ã€æ ‡å‡†å·®1çš„æ­£æ€åˆ†å¸ƒéšæœºå¼ é‡\t|size(å¼ é‡å½¢çŠ¶)|\n",
        "|torch.arange|\tç”Ÿæˆç­‰å·®æ•°åˆ—å¼ é‡ï¼ˆç±»ä¼¼Pythonçš„rangeï¼‰|\tstart(èµ·å§‹å€¼)ã€end(ç»ˆæ­¢å€¼)ã€step(æ­¥é•¿)|\n",
        "|torch.linspace|\tç”Ÿæˆå›ºå®šæ•°é‡çš„å‡åŒ€é—´éš”å¼ é‡ï¼ˆåŒ…å«ç»ˆç‚¹ï¼‰\t|startã€endã€steps(é—´éš”æ•°)|\n",
        "|torch.logspace|\tç”Ÿæˆå¯¹æ•°å°ºåº¦çš„å‡åŒ€é—´éš”å¼ é‡\t|startã€endã€stepsã€base(å¯¹æ•°åŸºï¼Œé»˜è®¤10)|\n",
        "|torch.eye|\tç”Ÿæˆå•ä½çŸ©é˜µï¼ˆå¯¹è§’çº¿1ï¼Œå…¶ä½™0ï¼‰\t|n(è¡Œæ•°)ã€m(åˆ—æ•°ï¼Œé»˜è®¤ç­‰äºn)|\n",
        "|torch.empty|\tç”Ÿæˆæœªåˆå§‹åŒ–å¼ é‡ï¼ˆå†…å­˜æ®‹ç•™å€¼ï¼Œé€Ÿåº¦å¿«ï¼‰| size(å¼ é‡å½¢çŠ¶)|\n",
        "|torch.full|\tç”Ÿæˆå…¨ä¸ºæŒ‡å®šå€¼çš„å¼ é‡\t|size(å½¢çŠ¶)ã€fill_value(å¡«å……å€¼ï¼‰|\n",
        "\n"
      ],
      "metadata": {
        "id": "4ON8Pr2JaKy0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# 1. ä»åˆ—è¡¨åˆ›å»ºå¼ é‡ï¼ŒæŒ‡å®šè¿½æ¢¯åº¦\n",
        "# åªæœ‰æµ®ç‚¹æ•°æ‰å¯ä»¥è®¾ç½®æ¢¯åº¦\n",
        "a = torch.tensor([1.0, 2, 3], requires_grad=True)\n",
        "print(\"torch.tensoråˆ›å»ºï¼š\", a)  # è¾“å‡ºï¼štensor([1, 2, 3], requires_grad=True)\n",
        "\n",
        "# 2. ç”Ÿæˆ2è¡Œ3åˆ—çš„å…¨0å¼ é‡\n",
        "b = torch.zeros(2, 3)\n",
        "print(\"torch.zerosåˆ›å»ºï¼š\\n\", b)  # è¾“å‡º2x3çš„0çŸ©é˜µ\n",
        "\n",
        "# 3. ç”Ÿæˆ0åˆ°10ã€æ­¥é•¿2çš„ç­‰å·®æ•°åˆ—\n",
        "c = torch.arange(0, 10, 2)\n",
        "print(\"torch.arangeåˆ›å»ºï¼š\", c)  # è¾“å‡ºï¼štensor([0, 2, 4, 6, 8])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Db1SsyEiaXSv",
        "outputId": "fd16dea4-2169-49c2-9a47-422bfeb592d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.tensoråˆ›å»ºï¼š tensor([1., 2., 3.], requires_grad=True)\n",
            "torch.zerosåˆ›å»ºï¼š\n",
            " tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "torch.arangeåˆ›å»ºï¼š tensor([0, 2, 4, 6, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2 å…ƒç´ çº§è¿ç®—ï¼šé€å…ƒç´ çš„åŠ å‡ä¹˜é™¤ä¸å‡½æ•°\n",
        "å¯¹å¼ é‡ä¸­æ¯ä¸ªå…ƒç´ å•ç‹¬æ“ä½œï¼Œè¦æ±‚è¾“å…¥å¼ é‡å½¢çŠ¶ç›¸åŒï¼ˆæˆ–æ»¡è¶³å¹¿æ’­æ¡ä»¶ï¼‰ã€‚\n",
        "##2.1 åŸºç¡€ç®—æœ¯è¿ç®—\n",
        "# PyTorch é€å…ƒç´ æ•°å­¦è¿ç®—é€ŸæŸ¥è¡¨\n",
        "\n",
        "## ğŸ“Œ åŸºç¡€æ“ä½œå¯¹ç…§è¡¨\n",
        "\n",
        "| æ“ä½œ        | åŠŸèƒ½æè¿°                     | è¯­æ³•ç¤ºä¾‹                                 | è¡¥å……è¯´æ˜ |\n",
        "|-------------|------------------------------|------------------------------------------|--------|\n",
        "| `torch.add` | é€å…ƒç´ åŠ æ³•                   | `torch.add(a, b, alpha=2)`               | ç­‰ä»·äº `a + alpha * b`ï¼›`alpha` å¯é€‰ï¼Œé»˜è®¤ä¸º1 |\n",
        "| `torch.sub` | é€å…ƒç´ å‡æ³•                   | `torch.sub(a, b)`                        | ç­‰ä»·äº `a - b` |\n",
        "| `torch.mul` | é€å…ƒç´ ä¹˜æ³•ï¼ˆéçŸ©é˜µä¹˜ï¼‰       | `torch.mul(a, b)`                        | ç­‰ä»·äº `a * b`ï¼›æ³¨æ„ä¸æ˜¯ `torch.mm` æˆ– `@` |\n",
        "| `torch.div` | é€å…ƒç´ é™¤æ³•                   | `torch.div(a, b)`                        | é»˜è®¤ä¸ºæµ®ç‚¹é™¤æ³•ï¼›å¯æŒ‡å®š `rounding_mode='floor'` æˆ– `'trunc'` |\n",
        "| `torch.pow` | é€å…ƒç´ å¹‚è¿ç®—                 | `torch.pow(a, 2)`                        | æ”¯æŒæ ‡é‡æˆ–å¼ é‡ä½œä¸ºæŒ‡æ•°ï¼Œå¦‚ `torch.pow(a, b)` |\n",
        "| `torch.sqrt`| é€å…ƒç´ å¹³æ–¹æ ¹                 | `torch.sqrt(a)`                          | è¾“å…¥å¿…é¡» â‰¥ 0ï¼Œå¦åˆ™è¿”å› `nan` |\n",
        "| `torch.exp` | é€å…ƒç´ è‡ªç„¶æŒ‡æ•°ï¼ˆ$e^x$ï¼‰     | `torch.exp(a)`                           | å¸¸ç”¨äºæ¿€æ´»å‡½æ•°ï¼ˆå¦‚ Softmaxï¼‰å‰å¤„ç† |\n",
        "| `torch.log` | é€å…ƒç´ è‡ªç„¶å¯¹æ•°ï¼ˆ$\\ln x$ï¼‰   | `torch.log(a)`                           | è¦æ±‚ `a > 0`ï¼Œå¦åˆ™è¿”å› `nan` æˆ– `-inf` |\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ’¡ ä½¿ç”¨å°è´´å£«\n",
        "\n",
        "- **å¹¿æ’­æ”¯æŒ**ï¼šæ‰€æœ‰ä¸Šè¿°æ“ä½œéƒ½æ”¯æŒå¹¿æ’­ï¼ˆbroadcastingï¼‰ï¼Œå³ä¸åŒå½¢çŠ¶çš„å¼ é‡åœ¨æ»¡è¶³å¹¿æ’­è§„åˆ™æ—¶å¯è‡ªåŠ¨å¯¹é½ã€‚\n",
        "- **In-place æ“ä½œ**ï¼šå¤§å¤šæ•°å‡½æ•°æœ‰ in-place ç‰ˆæœ¬ï¼ˆä»¥ `_` ç»“å°¾ï¼‰ï¼Œä¾‹å¦‚ `a.add_(b)` ä¼šç›´æ¥ä¿®æ”¹ `a`ï¼ŒèŠ‚çœå†…å­˜ä½†éœ€è°¨æ…ä½¿ç”¨ã€‚\n",
        "- **æ•°å€¼ç¨³å®šæ€§**ï¼šä½¿ç”¨ `torch.log` æˆ– `torch.sqrt` æ—¶ï¼Œç¡®ä¿è¾“å…¥æ»¡è¶³å®šä¹‰åŸŸè¦æ±‚ï¼Œé¿å…å‡ºç° `nan` æˆ– `inf`ã€‚"
      ],
      "metadata": {
        "id": "iF0taC62eWrc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "a = torch.tensor([1.0, 4.0, 9.0])\n",
        "b = torch.tensor([2.0, 2.0, 2.0])\n",
        "\n",
        "print(torch.add(a, b, alpha=0.5))   # è¾“å‡º: tensor([ 2.,  5., 10.])\n",
        "print(torch.mul(a, b))              # è¾“å‡º: tensor([ 2.,  8., 18.])\n",
        "print(torch.sqrt(a))                # è¾“å‡º: tensor([1., 2., 3.])\n",
        "print(torch.log(a))                 # è¾“å‡º: tensor([0.0000, 1.3863, 2.1972])\n",
        "a.add_(b)\n",
        "print(a)                            # è¾“å‡º: tensor([ 3.,  6., 11.])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaR6mxO0h4J7",
        "outputId": "eee6a92a-f2a6-461f-c41f-58bbede0f430"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 2.,  5., 10.])\n",
            "tensor([ 2.,  8., 18.])\n",
            "tensor([1., 2., 3.])\n",
            "tensor([0.0000, 1.3863, 2.1972])\n",
            "tensor([ 3.,  6., 11.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.2 ç»Ÿè®¡ç±»è¿ç®—\n",
        "### ğŸ“Š åŸºç¡€ç»Ÿè®¡è¿ç®—\n",
        "\n",
        "| æ“ä½œ | åŠŸèƒ½æè¿° | è¯­æ³•ç¤ºä¾‹ | è¡¥å……è¯´æ˜ |\n",
        "|------|----------|----------|----------|\n",
        "| `torch.sum` | è®¡ç®—å¼ é‡å…ƒç´ æ€»å’Œ | `torch.sum(a)` / `torch.sum(a, dim=0)` | æ”¯æŒæ²¿ç‰¹å®šç»´åº¦æ±‚å’Œï¼Œ`keepdim=True`ä¿ç•™ç»´åº¦ |\n",
        "| `torch.mean` | è®¡ç®—å¼ é‡å…ƒç´ å‡å€¼ | `torch.mean(a)` / `torch.mean(a, dim=1)` | æ•°æ®ç±»å‹å¿…é¡»ä¸ºæµ®ç‚¹å‹ï¼Œå¦åˆ™æŠ¥é”™ |\n",
        "| `torch.std` | è®¡ç®—æ ‡å‡†å·® | `torch.std(a, unbiased=True)` | `unbiased=False`ä½¿ç”¨æ€»ä½“æ ‡å‡†å·® |\n",
        "| `torch.var` | è®¡ç®—æ–¹å·® | `torch.var(a, unbiased=True)` | ä¸ `std` ç±»ä¼¼ï¼Œå¯é€‰æ— åä¼°è®¡ |\n",
        "| `torch.min` | æœ€å°å€¼åŠç´¢å¼• | `torch.min(a)` / `torch.min(a, dim=1)` | è¿”å› `(values, indices)` å…ƒç»„ |\n",
        "| `torch.max` | æœ€å¤§å€¼åŠç´¢å¼• | `torch.max(a)` / `torch.max(a, dim=0)` | è¿”å› `(values, indices)` å…ƒç»„ |\n",
        "| `torch.argmin` | æœ€å°å€¼ç´¢å¼• | `torch.argmin(a, dim=0)` | è¿”å›ç´¢å¼•ä½ç½®ï¼Œä¸è¿”å›å€¼æœ¬èº« |\n",
        "| `torch.argmax` | æœ€å¤§å€¼ç´¢å¼• | `torch.argmax(a, dim=1)` | è¿”å›ç´¢å¼•ä½ç½®ï¼Œä¸è¿”å›å€¼æœ¬èº« |\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ§® é«˜çº§ç»Ÿè®¡è¿ç®—\n",
        "\n",
        "| æ“ä½œ | åŠŸèƒ½æè¿° | è¯­æ³•ç¤ºä¾‹ | è¡¥å……è¯´æ˜ |\n",
        "|------|----------|----------|----------|\n",
        "| `torch.median` | ä¸­ä½æ•° | `torch.median(a)` / `torch.median(a, dim=1)` | è¿”å› `(values, indices)` å…ƒç»„ |\n",
        "| `torch.mode` | ä¼—æ•° | `torch.mode(a, dim=0)` | è¿”å› `(values, indices)` å…ƒç»„ |\n",
        "| `torch.quantile` | åˆ†ä½æ•° | `torch.quantile(a, q=0.5)` | `q` ä¸ºåˆ†ä½ç‚¹ (0~1)ï¼Œä»…æ”¯æŒä¸€ç»´å¼ é‡æˆ–æŒ‡å®šç»´åº¦ |\n",
        "| `torch.topk` | æœ€å¤§çš„ k ä¸ªå€¼ | `torch.topk(a, k=3, dim=1)` | è¿”å› `(values, indices)` å…ƒç»„ï¼ŒæŒ‰é™åºæ’åˆ— |\n",
        "| `torch.sort` | æ’åº | `torch.sort(a, dim=0, descending=False)` | è¿”å› `(values, indices)` å…ƒç»„ |\n",
        "| `torch.unique` | å»é‡å¹¶æ’åº | `torch.unique(a, return_counts=True)` | å¯é€‰æ‹©è¿”å›è®¡æ•° (`return_counts=True`) |\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ’¡ ä½¿ç”¨å°è´´å£«\n",
        "\n",
        "- **ç»´åº¦å‚æ•°**ï¼šå¤§éƒ¨åˆ†ç»Ÿè®¡å‡½æ•°æ”¯æŒ `dim` å‚æ•°ï¼Œç”¨äºæ²¿ç‰¹å®šè½´è®¡ç®—ã€‚ä¸æŒ‡å®šæ—¶é»˜è®¤å¯¹å…¨éƒ¨å…ƒç´ æ“ä½œã€‚\n",
        "- **ä¿æŒç»´åº¦**ï¼šä½¿ç”¨ `keepdim=True` å¯ä¿ç•™è¾“å‡ºå¼ é‡çš„ç»´åº¦ä¿¡æ¯ï¼Œä¾¿äºåç»­è®¡ç®—ã€‚\n",
        "- **æ•°æ®ç±»å‹**ï¼š`mean`ã€`std`ã€`var` ç­‰å‡½æ•°è¦æ±‚è¾“å…¥ä¸ºæµ®ç‚¹ç±»å‹ï¼Œæ•´æ•°å¼ é‡éœ€å…ˆè½¬æ¢ï¼ˆå¦‚ `.float()`ï¼‰ã€‚\n",
        "- **NaN å¤„ç†**ï¼šç»Ÿè®¡å‡½æ•°é€šå¸¸ä¼šä¼ æ’­ NaN å€¼ï¼ˆå¦‚å« NaN çš„åŒºåŸŸç»“æœä¸º NaNï¼‰ï¼Œå¯ç”¨ `torch.nanmean` ç­‰å‡½æ•°å¿½ç•¥ NaNã€‚\n",
        "\n",
        "---\n",
        "> âš ï¸ æ³¨æ„ï¼šæŸäº›å‡½æ•°ï¼ˆå¦‚ `quantile`ï¼‰åœ¨æ—§ç‰ˆ PyTorch ä¸­å¯èƒ½ä¸å¯ç”¨ï¼Œå»ºè®®æ£€æŸ¥ç‰ˆæœ¬å…¼å®¹æ€§ã€‚"
      ],
      "metadata": {
        "id": "uaUbeScUh3VY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "a = torch.tensor([[1.0, 4.0, 3.0],\n",
        "                  [2.0, 1.0, 6.0]])\n",
        "\n",
        "print(torch.sum(a))                 # è¾“å‡º: tensor(17.)\n",
        "print(torch.mean(a, dim=1))         # è¾“å‡º: tensor([2.6667, 3.0000])\n",
        "print(torch.std(a, unbiased=False)) # è¾“å‡º: tensor(1.7512)\n",
        "print(torch.min(a, dim=0))          # è¾“å‡º: values=tensor([1., 1., 3.]), indices=tensor([0, 1, 0])\n",
        "print(torch.argmax(a, dim=1))       # è¾“å‡º: tensor([1, 2])"
      ],
      "metadata": {
        "id": "jMOQiQP7i4Sl",
        "outputId": "c04d0b59-c1df-4ec6-f008-14b0ab09984c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(17.)\n",
            "tensor([2.6667, 3.0000])\n",
            "tensor(1.7717)\n",
            "torch.return_types.min(\n",
            "values=tensor([1., 1., 3.]),\n",
            "indices=tensor([0, 1, 0]))\n",
            "tensor([1, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3 çŸ©é˜µè¿ç®—ï¼šçº¿æ€§ä»£æ•°æ ¸å¿ƒæ“ä½œ\n",
        "\n",
        "\n",
        "### ğŸ”¢ åŸºç¡€çŸ©é˜µè¿ç®—\n",
        "\n",
        "| æ“ä½œ | åŠŸèƒ½æè¿° | è¯­æ³•ç¤ºä¾‹ | è¡¥å……è¯´æ˜ |\n",
        "|------|----------|----------|----------|\n",
        "| `torch.mm` | çŸ©é˜µä¹˜æ³•ï¼ˆ2D Ã— 2Dï¼‰ | `torch.mm(A, B)` | A.shape[-1] == B.shape[-2] |\n",
        "| `torch.matmul` | é€šç”¨çŸ©é˜µä¹˜æ³• | `torch.matmul(A, B)` | æ”¯æŒæ‰¹é‡æ“ä½œå’Œå¹¿æ’­<br/>å¯¹äºæ›´é«˜ç»´åº¦å¼ é‡ï¼Œå»ºè®®ä½¿ç”¨ torch.matmul æˆ– @ è¿ç®—ç¬¦ |\n",
        "| `torch.bmm` | æ‰¹é‡çŸ©é˜µä¹˜æ³• | `torch.bmm(batch_A, batch_B)` | è¾“å…¥ä¸º 3D å¼ é‡ (batch, n, m)<br/>ç¬¬ä¸€ç»´åº¦å¿…é¡»ç›¸åŒï¼ˆæ‰¹æ¬¡å¤§å°ï¼‰<br/>ä¸“ä¸ºæ‰¹é‡æ“ä½œä¼˜åŒ–ï¼Œæ¯”å¾ªç¯è°ƒç”¨ torch.mm æ›´å¿«\n",
        " |\n",
        "| `@` è¿ç®—ç¬¦ | çŸ©é˜µä¹˜æ³•ï¼ˆPython 3.5+ï¼‰ | `A @ B` | ç­‰ä»·äº `torch.matmul(A, B)` |\n",
        "| `torch.dot` | å‘é‡ç‚¹ç§¯ | `torch.dot(a, b)` | ä»…é€‚ç”¨äº 1D å‘é‡ |\n",
        "| `torch.cross` | å‘é‡å‰ç§¯ | `torch.cross(a, b, dim=0)` | 3D å‘é‡å‰ç§¯ |\n",
        "| `torch.outer` | å‘é‡å¤–ç§¯ | `torch.outer(a, b)` | è¿”å›çŸ©é˜µ (len(a), len(b)) |\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ§® çŸ©é˜µåˆ†è§£ä¸å˜æ¢\n",
        "\n",
        "| æ“ä½œ | åŠŸèƒ½æè¿° | è¯­æ³•ç¤ºä¾‹ | è¡¥å……è¯´æ˜ |\n",
        "|------|----------|----------|----------|\n",
        "| `torch.inverse` | çŸ©é˜µæ±‚é€† | `torch.inverse(A)` | A å¿…é¡»ä¸ºæ–¹é˜µä¸”å¯é€† |\n",
        "| `torch.det` | è¡Œåˆ—å¼ | `torch.det(A)` | ä»…å¯¹æ–¹é˜µæœ‰æ•ˆ |\n",
        "| `torch.svd` | å¥‡å¼‚å€¼åˆ†è§£ | `U, S, V = torch.svd(A)` | A = U diag(S) V^T |\n",
        "| `torch.qr` | QR åˆ†è§£ | `Q, R = torch.qr(A)` | A = Q R |\n",
        "| `torch.eig` | ç‰¹å¾å€¼ä¸ç‰¹å¾å‘é‡ | `e, v = torch.eig(A, eigenvectors=True)` | ä»…æ”¯æŒå®çŸ©é˜µ |\n",
        "| `torch.cholesky` | Cholesky åˆ†è§£ | `L = torch.cholesky(A)` | A å¿…é¡»ä¸ºæ­£å®šçŸ©é˜µ |\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ§® çŸ©é˜µå±æ€§ä¸å˜æ¢\n",
        "\n",
        "| æ“ä½œ | åŠŸèƒ½æè¿° | è¯­æ³•ç¤ºä¾‹ | è¡¥å……è¯´æ˜ |\n",
        "|------|----------|----------|----------|\n",
        "| `torch.transpose` | çŸ©é˜µè½¬ç½® | `torch.transpose(A, 0, 1)` | äº¤æ¢ä¸¤ä¸ªç»´åº¦ |\n",
        "| `torch.t` | 2D å¼ é‡è½¬ç½® | `torch.t(A)` | ç­‰ä»·äº `A.T` |\n",
        "| `torch.trace` | çŸ©é˜µè¿¹ï¼ˆå¯¹è§’çº¿å’Œï¼‰ | `torch.trace(A)` | ä»…å¯¹æ–¹é˜µæœ‰æ•ˆ |\n",
        "| `torch.norm` | èŒƒæ•°è®¡ç®— | `torch.norm(A, p=2, dim=0)` | æ”¯æŒå¤šç§èŒƒæ•°ï¼ˆp=1,2,'fro','nuc'ç­‰ï¼‰ |\n",
        "| `torch.diag` | å¯¹è§’çº¿æå–/æ„é€  | `torch.diag(A)` / `torch.diag(v)` | å¯æå–å¯¹è§’çº¿æˆ–æ„é€ å¯¹è§’çŸ©é˜µ |\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## ğŸ’¡ ä½¿ç”¨å°è´´å£«\n",
        "\n",
        "- **çŸ©é˜µä¹˜æ³•é€‰æ‹©**ï¼š\n",
        "  - `torch.mm`: ä»…é™ 2D çŸ©é˜µä¹˜æ³•\n",
        "  - `torch.matmul`: é€šç”¨çŸ©é˜µä¹˜æ³•ï¼Œæ”¯æŒæ›´é«˜ç»´å¼ é‡å’Œå¹¿æ’­\n",
        "  - `@`: Python å†…ç½®çŸ©é˜µä¹˜æ³•è¿ç®—ç¬¦ï¼Œæ¨èä½¿ç”¨\n",
        "- **æ•°å€¼ç¨³å®šæ€§**ï¼šçŸ©é˜µæ±‚é€†å’Œåˆ†è§£æ“ä½œå¯¹æ•°å€¼ç²¾åº¦æ•æ„Ÿï¼Œè€ƒè™‘ä½¿ç”¨ `double` ç±»å‹æé«˜ç²¾åº¦\n",
        "- **GPU åŠ é€Ÿ**ï¼šæ‰€æœ‰çº¿æ€§ä»£æ•°æ“ä½œéƒ½æ”¯æŒ GPU è®¡ç®—ï¼Œåªéœ€å°†å¼ é‡ç§»åˆ° CUDA è®¾å¤‡ä¸Š\n",
        "- **æ¢¯åº¦è¿½è¸ª**ï¼šå¤§å¤šæ•°çº¿æ€§ä»£æ•°æ“ä½œæ”¯æŒè‡ªåŠ¨å¾®åˆ†ï¼Œå¯ç”¨äºæ·±åº¦å­¦ä¹ æ¨¡å‹\n",
        "\n",
        "> âš ï¸ æ³¨æ„ï¼šæŸäº›åˆ†è§£å‡½æ•°ï¼ˆå¦‚ `eig`ï¼‰åœ¨å¤æ•°åŸŸä¸Šçš„è¡Œä¸ºå¯èƒ½ä¸ NumPy ä¸åŒï¼Œå»ºè®®æŸ¥é˜…å®˜æ–¹æ–‡æ¡£ç¡®è®¤ç»†èŠ‚ã€‚"
      ],
      "metadata": {
        "id": "VSDuXJuNozO6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###bmm\n",
        "import torch\n",
        "\n",
        "# ç¤ºä¾‹ï¼šè®¡ç®—å¤šä¸ªæŸ¥è¯¢-é”®-å€¼çš„æ³¨æ„åŠ›æƒé‡\n",
        "batch_size, seq_len, d_k = 2, 4, 3\n",
        "queries = torch.randn(batch_size, seq_len, d_k)  # æŸ¥è¯¢çŸ©é˜µ\n",
        "keys = torch.randn(batch_size, seq_len, d_k)     # é”®çŸ©é˜µ\n",
        "\n",
        "# è®¡ç®—æ³¨æ„åŠ›åˆ†æ•° (queries @ keys^T)\n",
        "attn_scores = torch.bmm(queries, keys.transpose(1, 2))\n",
        "# ç»“æœå½¢çŠ¶: (2, 4, 4) - æ¯ä¸ªæ ·æœ¬çš„æ³¨æ„åŠ›çŸ©é˜µ\n",
        "\n",
        "print(f\"Attention scores shape: {attn_scores.shape}\")\n"
      ],
      "metadata": {
        "id": "_n706ILFqKfC",
        "outputId": "85b4bc74-64dd-44a3-ba41-022a927c8371",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention scores shape: torch.Size([2, 4, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4 å¼ é‡å˜å½¢ï¼šè°ƒæ•´å½¢çŠ¶ä¸ç»´åº¦é€ŸæŸ¥è¡¨\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ“ åŸºç¡€å½¢çŠ¶æ“ä½œ\n",
        "\n",
        "| æ“ä½œ | åŠŸèƒ½æè¿° | è¯­æ³•ç¤ºä¾‹ | è¡¥å……è¯´æ˜ |\n",
        "|------|----------|----------|----------|\n",
        "| `tensor.shape` / `tensor.size()` | æŸ¥çœ‹å¼ é‡å½¢çŠ¶ | `x.shape` | è¿”å› `torch.Size` å¯¹è±¡ |\n",
        "| `tensor.numel()` | å…ƒç´ æ€»æ•° | `x.numel()` | ç­‰ä»·äº `prod(x.shape)` |\n",
        "| `tensor.reshape(*shape)` | æ”¹å˜å½¢çŠ¶ï¼ˆè¿”å›æ–°è§†å›¾æˆ–æ‹·è´ï¼‰ | `x.reshape(2, -1)` | `-1` è‡ªåŠ¨æ¨æ–­è¯¥ç»´åº¦å¤§å° |\n",
        "| `tensor.view(*shape)` | æ”¹å˜å½¢çŠ¶ï¼ˆä»…è¿”å›è§†å›¾ï¼‰ | `x.view(4, 3)` | è¦æ±‚å†…å­˜è¿ç»­ï¼Œå¦åˆ™æŠ¥é”™ |\n",
        "| `tensor.resize_(*shape)` | **å°±åœ°**æ”¹å˜å½¢çŠ¶ï¼ˆå¯èƒ½ä¸¢å¤±æ•°æ®ï¼‰ | `x.resize_(2, 6)` | âš ï¸ å±é™©æ“ä½œï¼Œæ…ç”¨ |\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ” ç»´åº¦å˜æ¢\n",
        "\n",
        "| æ“ä½œ | åŠŸèƒ½æè¿° | è¯­æ³•ç¤ºä¾‹ | è¡¥å……è¯´æ˜ |\n",
        "|------|----------|----------|----------|\n",
        "| `tensor.unsqueeze(dim)` | å¢åŠ ä¸€ä¸ªç»´åº¦ï¼ˆå¤§å°ä¸º1ï¼‰ | `x.unsqueeze(0)` | ç›¸å½“äº `x[None, :]` |\n",
        "| `tensor.squeeze(dim=None)` | ç§»é™¤å¤§å°ä¸º1çš„ç»´åº¦ | `x.squeeze()` | è‹¥æŒ‡å®š `dim`ï¼Œä»…ç§»é™¤è¯¥ç»´ï¼ˆè‹¥ä¸º1ï¼‰ |\n",
        "| `tensor.transpose(dim0, dim1)` | äº¤æ¢ä¸¤ä¸ªç»´åº¦ | `x.transpose(0, 1)` | é€‚ç”¨äºä»»æ„ç»´åº¦å¼ é‡ |\n",
        "| `tensor.t()` | 2D å¼ é‡è½¬ç½® | `x.t()` | ä»…é™ 2Dï¼Œç­‰ä»·äº `x.T` |\n",
        "| `tensor.permute(*dims)` | é‡æ’æ‰€æœ‰ç»´åº¦é¡ºåº | `x.permute(2, 0, 1)` | ç±»ä¼¼ NumPy çš„ `transpose` |\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ§© é«˜çº§é‡ç»„æ“ä½œ\n",
        "\n",
        "| æ“ä½œ | åŠŸèƒ½æè¿° | è¯­æ³•ç¤ºä¾‹ | è¡¥å……è¯´æ˜ |\n",
        "|------|----------|----------|----------|\n",
        "| `torch.cat(tensors, dim=0)` | æ²¿ç°æœ‰ç»´åº¦æ‹¼æ¥ | `torch.cat([a, b], dim=1)` | å¼ é‡åœ¨å…¶ä»–ç»´åº¦ä¸Šå¿…é¡»ä¸€è‡´ |\n",
        "| `torch.stack(tensors, dim=0)` | æ²¿æ–°ç»´åº¦å †å  | `torch.stack([a, b], dim=0)` | æ‰€æœ‰å¼ é‡å½¢çŠ¶å¿…é¡»å®Œå…¨ç›¸åŒ |\n",
        "| `torch.chunk(tensor, chunks, dim=0)` | åˆ†å‰²ä¸ºè‹¥å¹²å— | `torch.chunk(x, 3, dim=1)` | å°½å¯èƒ½å‡åˆ†ï¼Œæœ€åä¸€å—å¯èƒ½è¾ƒå° |\n",
        "| `torch.split(tensor, split_size_or_sections, dim=0)` | æŒ‰æŒ‡å®šå¤§å°åˆ†å‰² | `torch.split(x, [2, 3], dim=1)` | å¯æŒ‡å®šæ¯å—å¤§å° |\n",
        "| `torch.flatten(input, start_dim=0, end_dim=-1)` | å±•å¹³æŒ‡å®šç»´åº¦èŒƒå›´ | `torch.flatten(x, 1)` | å¸¸ç”¨äº CNN åˆ°å…¨è¿æ¥å±‚è¿‡æ¸¡ |\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”„ ç‰¹æ®Šå˜å½¢æ“ä½œ\n",
        "\n",
        "| æ“ä½œ | åŠŸèƒ½æè¿° | è¯­æ³•ç¤ºä¾‹ | è¡¥å……è¯´æ˜ |\n",
        "|------|----------|----------|----------|\n",
        "| `torch.repeat_interleave(input, repeats, dim=None)` | é‡å¤å…ƒç´  | `x.repeat_interleave(2, dim=0)` | æ¯ä¸ªå…ƒç´ é‡å¤å¤šæ¬¡ |\n",
        "| `tensor.repeat(*sizes)` | æ²¿å„ç»´åº¦é‡å¤æ•´ä¸ªå¼ é‡ | `x.repeat(2, 3)` | ä¸åŒäº `expand`ï¼Œä¼šå¤åˆ¶æ•°æ® |\n",
        "| `tensor.expand(*sizes)` | å¹¿æ’­åˆ°æ›´å¤§å½¢çŠ¶ï¼ˆä¸å¤åˆ¶æ•°æ®ï¼‰ | `x.expand(3, -1)` | `-1` è¡¨ç¤ºä¿æŒåŸå°ºå¯¸ |\n",
        "| `torch.tile(input, dims)` | é‡å¤å¼ é‡ï¼ˆç±»ä¼¼ NumPy tileï¼‰ | `torch.tile(x, (2, 1))` | PyTorch 1.8+ æ”¯æŒ |\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ’¡ ä½¿ç”¨å°è´´å£«\n",
        "\n",
        "### âœ… `view` vs `reshape`\n",
        "- **`view`**: ä»…å½“å¼ é‡å†…å­˜è¿ç»­æ—¶å¯ç”¨ï¼Œè¿”å›è§†å›¾ï¼ˆä¸æ‹·è´æ•°æ®ï¼‰\n",
        "- **`reshape`**: æ€»æ˜¯å®‰å…¨ï¼Œå¿…è¦æ—¶è‡ªåŠ¨æ‹·è´æ•°æ®\n",
        "```python\n",
        "x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "y = x.t()  # è½¬ç½®åå†…å­˜ä¸è¿ç»­\n",
        "# y.view(-1)  # âŒ æŠ¥é”™ï¼\n",
        "z = y.reshape(-1)  # âœ… å®‰å…¨\n",
        "```\n",
        "\n",
        "### âœ… å¸¸è§æ¨¡å¼\n",
        "```python\n",
        "# æ·»åŠ  batch ç»´åº¦\n",
        "x = torch.randn(3, 224, 224)\n",
        "x_batch = x.unsqueeze(0)  # (1, 3, 224, 224)\n",
        "\n",
        "# ç§»é™¤å•ä¾‹ç»´åº¦\n",
        "x = torch.randn(1, 3, 1, 224, 224)\n",
        "x_clean = x.squeeze()     # (3, 224, 224)\n",
        "\n",
        "# NHWC â†’ NCHWï¼ˆå›¾åƒæ ¼å¼è½¬æ¢ï¼‰\n",
        "images_nhwc = torch.randn(32, 224, 224, 3)\n",
        "images_nchw = images_nhwc.permute(0, 3, 1, 2)  # (32, 3, 224, 224)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§ª å®æˆ˜ç¤ºä¾‹\n",
        "\n",
        "```python\n",
        "import torch\n",
        "\n",
        "# åŸå§‹å¼ é‡\n",
        "x = torch.arange(12).reshape(3, 4)\n",
        "print(\"åŸå§‹:\", x.shape)  # torch.Size([3, 4])\n",
        "\n",
        "# reshape/view\n",
        "y = x.reshape(2, 6)\n",
        "print(\"reshape:\", y.shape)  # torch.Size([2, 6])\n",
        "\n",
        "# unsqueeze/squeeze\n",
        "z = x.unsqueeze(1)  # (3, 1, 4)\n",
        "z_squeezed = z.squeeze(1)  # (3, 4)\n",
        "\n",
        "# permute\n",
        "img = torch.randn(2, 3, 32, 32)  # (N, C, H, W)\n",
        "img_hwc = img.permute(0, 2, 3, 1)  # (N, H, W, C)\n",
        "\n",
        "# flatten for MLP\n",
        "features = torch.flatten(img, 1)  # (2, 3072)\n",
        "\n",
        "# repeat vs expand\n",
        "a = torch.tensor([1, 2, 3])\n",
        "b = a.repeat(2)      # tensor([1, 2, 3, 1, 2, 3]) - å¤åˆ¶æ•°æ®\n",
        "c = a.expand(2, -1)  # shape (2, 3) - å…±äº«å†…å­˜\n",
        "```\n",
        "\n",
        "> âš ï¸ æ³¨æ„ï¼š\n",
        "> - `view`/`reshape` è¦æ±‚å…ƒç´ æ€»æ•°ä¸å˜\n",
        "> - `squeeze` é»˜è®¤ç§»é™¤æ‰€æœ‰å¤§å°ä¸º1çš„ç»´åº¦ï¼ŒæŒ‡å®š `dim` å¯ç²¾ç¡®æ§åˆ¶\n",
        "> - `expand` ä¸åˆ†é…æ–°å†…å­˜ï¼Œé€‚åˆä¸´æ—¶å¹¿æ’­ï¼›`repeat` ä¼šå¤åˆ¶æ•°æ®ï¼Œé€‚åˆéœ€è¦ç‹¬ç«‹å‰¯æœ¬çš„åœºæ™¯"
      ],
      "metadata": {
        "id": "32F5IhMiBrYI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5 æ¢¯åº¦ä¸è®¡ç®—å›¾ï¼šPyTorchè‡ªåŠ¨å¾®åˆ†æ ¸å¿ƒ\n",
        "\n",
        "## ğŸ§  æ ¸å¿ƒæ¦‚å¿µ\n",
        "\n",
        "### 1. **è®¡ç®—å›¾ï¼ˆComputational Graphï¼‰**\n",
        "- PyTorch åŠ¨æ€æ„å»º**åå‘è®¡ç®—å›¾**ï¼ˆReverse-mode ADï¼‰\n",
        "- æ¯æ¬¡å‰å‘ä¼ æ’­æ—¶è®°å½•æ“ä½œï¼Œç”¨äºåå‘ä¼ æ’­\n",
        "- å›¾ç»“æ„åœ¨ `backward()` åè‡ªåŠ¨é‡Šæ”¾ï¼ˆé™¤éè®¾ç½® `retain_graph=True`ï¼‰\n",
        "\n",
        "### 2. **æ¢¯åº¦è¿½è¸ªï¼ˆGradient Trackingï¼‰**\n",
        "- åªæœ‰ `requires_grad=True` çš„å¼ é‡æ‰ä¼šå‚ä¸æ¢¯åº¦è®¡ç®—\n",
        "- æ“ä½œç»“æœçš„ `requires_grad` ç»§æ‰¿è‡ªè¾“å…¥å¼ é‡ï¼ˆä»»ä¸€ä¸º True åˆ™ç»“æœä¸º Trueï¼‰\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”‘ æ ¸å¿ƒå±æ€§ä¸æ–¹æ³•\n",
        "\n",
        "| å±æ€§/æ–¹æ³• | åŠŸèƒ½æè¿° | ç¤ºä¾‹ |\n",
        "|-----------|----------|--------------------------------------------|\n",
        "| `tensor.requires_grad` | æ˜¯å¦éœ€è¦è®¡ç®—æ¢¯åº¦ | `x = torch.tensor(1.0, requires_grad=True)` |\n",
        "| `tensor.grad` | å­˜å‚¨æ¢¯åº¦å€¼ï¼ˆåå‘ä¼ æ’­åï¼‰ | `print(x.grad)` |\n",
        "| `tensor.grad_fn` | æŒ‡å‘åˆ›å»ºè¯¥å¼ é‡çš„å‡½æ•° | `y.grad_fn` è¿”å› `<AddBackward0>` |\n",
        "| `tensor.backward()` | æ‰§è¡Œåå‘ä¼ æ’­ | `loss.backward()` |\n",
        "| `torch.no_grad()` | ä¸´æ—¶ç¦ç”¨æ¢¯åº¦è®¡ç®— | `with torch.no_grad(): ...` |\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“ˆ åŸºæœ¬å·¥ä½œæµç¨‹\n",
        "\n",
        "```python\n",
        "import torch\n",
        "\n",
        "# 1. åˆ›å»ºéœ€è¦æ¢¯åº¦çš„å¼ é‡\n",
        "x = torch.tensor(2.0, requires_grad=True)\n",
        "w = torch.tensor(3.0, requires_grad=True)\n",
        "b = torch.tensor(1.0, requires_grad=True)\n",
        "\n",
        "# 2. å‰å‘ä¼ æ’­ï¼ˆæ„å»ºè®¡ç®—å›¾ï¼‰\n",
        "y = w * x + b  # y = 3*2 + 1 = 7\n",
        "loss = y ** 2  # loss = 49\n",
        "\n",
        "# 3. åå‘ä¼ æ’­\n",
        "loss.backward()\n",
        "\n",
        "# 4. æŸ¥çœ‹æ¢¯åº¦\n",
        "print(f\"x.grad: {x.grad}\")    # 84.0 (d(loss)/dx = 2*y*w = 2*7*3)\n",
        "print(f\"w.grad: {w.grad}\")    # 56.0 (d(loss)/dw = 2*y*x = 2*7*2)\n",
        "print(f\"b.grad: {b.grad}\")    # 14.0 (d(loss)/db = 2*y = 2*7)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## âš™ï¸ é«˜çº§æ§åˆ¶é€‰é¡¹\n",
        "\n",
        "### 1. **æ¢¯åº¦æ¸…é›¶**\n",
        "```python\n",
        "# æ–¹æ³•1ï¼šç›´æ¥ç½®é›¶\n",
        "optimizer.zero_grad()  # æ¨èï¼ˆä¼˜åŒ–å™¨æ–¹å¼ï¼‰\n",
        "\n",
        "# æ–¹æ³•2ï¼šæ‰‹åŠ¨æ¸…é›¶\n",
        "x.grad.zero_()  # æ³¨æ„ï¼šå¿…é¡»æ˜¯å°±åœ°æ“ä½œ\n",
        "\n",
        "# æ–¹æ³•3ï¼šé‡æ–°åˆ›å»ºï¼ˆä¸æ¨èï¼‰\n",
        "x.grad = None  # PyTorch 1.7+ æ”¯æŒï¼Œä¼šè‡ªåŠ¨é‡æ–°åˆ†é…\n",
        "```\n",
        "\n",
        "### 2. **åœæ­¢æ¢¯åº¦ä¼ æ’­**\n",
        "```python\n",
        "# æ–¹å¼1ï¼šdetach() - è¿”å›æ–°å¼ é‡ï¼Œæ— æ¢¯åº¦\n",
        "z = y.detach()\n",
        "\n",
        "# æ–¹å¼2ï¼štorch.no_grad() - ä¸Šä¸‹æ–‡ç®¡ç†å™¨\n",
        "with torch.no_grad():\n",
        "    prediction = model(x)\n",
        "\n",
        "# æ–¹å¼3ï¼šrequires_grad_(False) - å°±åœ°ä¿®æ”¹\n",
        "x.requires_grad_(False)\n",
        "```\n",
        "\n",
        "### 3. **ä¿ç•™è®¡ç®—å›¾**\n",
        "```python\n",
        "# é»˜è®¤æƒ…å†µä¸‹ï¼Œbackward() åè®¡ç®—å›¾è¢«é‡Šæ”¾\n",
        "loss.backward(retain_graph=True)  # ä¿ç•™å›¾ï¼Œå¯å¤šæ¬¡è°ƒç”¨ backward()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§© å¤æ‚åœºæ™¯å¤„ç†\n",
        "\n",
        "### 1. **æ ‡é‡ vs éæ ‡é‡è¾“å‡º**\n",
        "```python\n",
        "# æ ‡é‡è¾“å‡ºï¼ˆæœ€å¸¸è§ï¼‰\n",
        "loss = torch.sum(y)  # æˆ– y.mean(), y.sum()\n",
        "loss.backward()      # ç›´æ¥è°ƒç”¨\n",
        "\n",
        "# éæ ‡é‡è¾“å‡ºï¼ˆéœ€è¦æä¾› grad_tensorsï¼‰\n",
        "y = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
        "y.backward(torch.tensor([1.0, 1.0, 1.0]))  # æŒ‡å®šæ¯ä¸ªè¾“å‡ºçš„æ¢¯åº¦æƒé‡\n",
        "```\n",
        "\n",
        "### 2. **æ¢¯åº¦ç´¯åŠ **\n",
        "```python\n",
        "# æ¢¯åº¦ä¸ä¼šè‡ªåŠ¨æ¸…é›¶ï¼Œè€Œæ˜¯ç´¯åŠ \n",
        "for i in range(2):\n",
        "    loss = (x ** 2).sum()\n",
        "    loss.backward()\n",
        "    \n",
        "print(x.grad)  # æ˜¯å•æ¬¡æ¢¯åº¦çš„2å€\n",
        "```\n",
        "\n",
        "### 3. **è‡ªå®šä¹‰æ¢¯åº¦å‡½æ•°**\n",
        "```python\n",
        "class CustomFunction(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        ctx.save_for_backward(input)\n",
        "        return input.clamp(min=0)\n",
        "    \n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        input, = ctx.saved_tensors\n",
        "        grad_input = grad_output.clone()\n",
        "        grad_input[input < 0] = 0\n",
        "        return grad_input\n",
        "\n",
        "# ä½¿ç”¨è‡ªå®šä¹‰å‡½æ•°\n",
        "custom_relu = CustomFunction.apply\n",
        "output = custom_relu(x)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ›¡ï¸ æœ€ä½³å®è·µä¸æ³¨æ„äº‹é¡¹\n",
        "\n",
        "### âœ… æ¨èåšæ³•\n",
        "- **ä½¿ç”¨ä¼˜åŒ–å™¨ç®¡ç†æ¢¯åº¦æ¸…é›¶**ï¼š`optimizer.zero_grad()`\n",
        "- **æ¨ç†æ—¶ç¦ç”¨æ¢¯åº¦**ï¼š`with torch.no_grad():`\n",
        "- **æ£€æŸ¥æ¢¯åº¦æ˜¯å¦å­˜åœ¨**ï¼š`if tensor.grad is not None:`\n",
        "- **é¿å…å°±åœ°æ“ä½œ**ï¼šå¦‚ `x += 1` å¯èƒ½ç ´åè®¡ç®—å›¾\n",
        "\n",
        "### âš ï¸ å¸¸è§é™·é˜±\n",
        "| é—®é¢˜ | è§£å†³æ–¹æ¡ˆ |\n",
        "|------|----------|\n",
        "| **æ¢¯åº¦çˆ†ç‚¸/æ¶ˆå¤±** | æ¢¯åº¦è£å‰ªã€æƒé‡åˆå§‹åŒ–ã€å½’ä¸€åŒ– |\n",
        "| **å†…å­˜æ³„æ¼** | é¿å…åœ¨è®­ç»ƒå¾ªç¯ä¸­ä¿å­˜ `.grad` å¼•ç”¨ |\n",
        "| **å°±åœ°æ“ä½œé”™è¯¯** | ä½¿ç”¨ `x = x + 1` è€Œé `x += 1` |\n",
        "| **æ¢¯åº¦æœªæ¸…é›¶** | æ¯ä¸ª batch å¼€å§‹å‰è°ƒç”¨ `zero_grad()` |\n",
        "\n",
        "### ğŸ” è°ƒè¯•æŠ€å·§\n",
        "```python\n",
        "# æ£€æŸ¥å¼ é‡æ˜¯å¦å‚ä¸æ¢¯åº¦è®¡ç®—\n",
        "print(x.requires_grad)\n",
        "\n",
        "# æ£€æŸ¥è®¡ç®—å›¾è¿æ¥\n",
        "print(y.grad_fn)\n",
        "\n",
        "# æ£€æŸ¥æ¢¯åº¦å€¼\n",
        "print(x.grad)\n",
        "\n",
        "# æ£€æŸ¥æ˜¯å¦æœ‰ NaN æ¢¯åº¦\n",
        "if torch.isnan(x.grad).any():\n",
        "    print(\"Gradient contains NaN!\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§ª å®Œæ•´è®­ç»ƒå¾ªç¯ç¤ºä¾‹\n",
        "\n",
        "```python\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# æ¨¡å‹å’Œæ•°æ®\n",
        "model = nn.Linear(10, 1)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "# è®­ç»ƒå¾ªç¯\n",
        "for epoch in range(100):\n",
        "    # å‰å‘ä¼ æ’­\n",
        "    inputs = torch.randn(32, 10)\n",
        "    targets = torch.randn(32, 1)\n",
        "    \n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, targets)\n",
        "    \n",
        "    # åå‘ä¼ æ’­\n",
        "    optimizer.zero_grad()  # æ¸…é›¶æ¢¯åº¦\n",
        "    loss.backward()        # è®¡ç®—æ¢¯åº¦\n",
        "    optimizer.step()       # æ›´æ–°å‚æ•°\n",
        "    \n",
        "    if epoch % 10 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {loss.item():.4f}')\n",
        "```\n",
        "\n",
        "> ğŸ’¡ **å…³é”®è¦ç‚¹**ï¼šPyTorch çš„è‡ªåŠ¨å¾®åˆ†æ˜¯**åŠ¨æ€çš„**ï¼ˆdefine-by-runï¼‰ï¼Œæ¯æ¬¡å‰å‘ä¼ æ’­éƒ½ä¼šé‡æ–°æ„å»ºè®¡ç®—å›¾ï¼Œè¿™ä½¿å¾—è°ƒè¯•å’Œæ§åˆ¶æ›´åŠ çµæ´»ã€‚"
      ],
      "metadata": {
        "id": "xfbDKSDXNt7l"
      }
    }
  ]
}